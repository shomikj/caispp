{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks - CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%run -i tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Convert y_train, y_test to be a list\n",
    "train_labels = [y for arr in train_labels for y in arr]\n",
    "test_labels = [y for arr in test_labels for y in arr]\n",
    "\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train images:\", train_images.shape)\n",
    "print(\"Train labels:\", len(train_labels)) \n",
    "print(\"Test images:\", test_images.shape)\n",
    "print(\"Test labels\", len(test_labels))\n",
    "print(\"Number of classes:\", len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def show_image(index):\n",
    "    print(classes[train_labels[index]])\n",
    "    plot = plt.imshow(train_images[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 1000 \n",
    "show_image(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train = train_images.astype('float32')\n",
    "X_test = test_images.astype('float32')\n",
    "\n",
    "# Normalize Features: Convert Pixels from the range 0-255 to 0-1\n",
    "X_train /= 255.\n",
    "X_test /= 255.\n",
    "\n",
    "# One-Hot Encoding for Labels: ['cat', 'dog'] => [(0,1), (1,0)]\n",
    "y_train = keras.utils.to_categorical(train_labels)\n",
    "y_test = keras.utils.to_categorical(test_labels)\n",
    "\n",
    "# Shuffle Data\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_test, y_test = shuffle(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorten Dataset (We would use all data in practice, but we don't have enough time :)\n",
    "PERCENT_DATA_USED = .10 \n",
    "\n",
    "num_train = int(PERCENT_DATA_USED * len(X_train))\n",
    "num_test = int(PERCENT_DATA_USED * len(X_test))\n",
    "X_train = X_train[:num_train]\n",
    "y_train = y_train[:num_train]\n",
    "X_test = X_test[:num_test]\n",
    "y_test = y_test[:num_test]\n",
    "\n",
    "print(len(X_train), len(y_train), len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CNN Model\n",
    "\n",
    "- [Convolutional Layers](https://keras.io/layers/convolutional/) \n",
    "    - filters: number of kernals (feature_detectors) in the layer\n",
    "    - kernal_size: size of the kernal\n",
    "    - activation: relu activation function typically used\n",
    "    - padding: how to perserve information in borders\n",
    "    - strides: how to slide kernal over the input (step size)\n",
    "- [Pooling layers](https://keras.io/layers/pooling/)\n",
    "   - max pooling: takes only the maximum pixel value from a region of pixels\n",
    "   - pool_size: region of pixels to consider\n",
    "- [Dropout](https://keras.io/layers/core/#dropout) \n",
    "    - randomly drop neurons during training, helps prevent overfitting\n",
    "    - rate: percentage of neurons to drop\n",
    "- [Batch norm layer](https://keras.io/layers/normalization/)\n",
    "    - normalizes data at a given point in the network, helps prevent overfitting\n",
    "- [Dense Layer](https://keras.io/layers/core/#dense) \n",
    "    - regular fully-connected layer in traditional NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), kernel_initializer='he_uniform', activation='relu', input_shape=(32, 32, 3), padding='same'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), kernel_initializer='he_uniform', activation='relu', padding='same'))  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
